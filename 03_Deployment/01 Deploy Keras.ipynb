{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "In this workbook, we will train a simple Keras MNIST CNN model and deploy that for inference\n",
    "\n",
    "Parts of this workbook are borrowed from [here](https://keras.io/examples/vision/mnist_convnet/)\n",
    "\n",
    "## 2. Imports and Dependencies.\n",
    "The few packages needed are loaded next. Particularly, `numpy`, `tensorflow`, `keras`, `mlflow` will be majorly used in this tutorial. `requests` package will be used for performing query. `json` is used to post and get response from the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 18:35:43.301898: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-12 18:35:43.301935: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import numpy as np\n",
    "from mlflow import pyfunc\n",
    "import cloudpickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from mlflow.utils.environment import _mlflow_conda_env\n",
    "\n",
    "# Setting a tracking uri to log the mlflow logs in a particular location tracked by \n",
    "from mlflow.tracking import MlflowClient\n",
    "tracking_uri = os.environ.get(\"TRACKING_URL\")\n",
    "client = MlflowClient(tracking_uri=tracking_uri)\n",
    "mlflow.set_tracking_uri(tracking_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 18:35:45.382578: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-11-12 18:35:45.382613: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-12 18:35:45.382637: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ov9ogvb8-58556b7474-d8g7w): /proc/driver/nvidia/version does not exist\n",
      "2021-11-12 18:35:45.382942: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 18:35:50.743054: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "422/422 [==============================] - 17s 40ms/step - loss: 0.3598 - accuracy: 0.8932 - val_loss: 0.0867 - val_accuracy: 0.9765\n",
      "Epoch 2/15\n",
      "422/422 [==============================] - 16s 38ms/step - loss: 0.1151 - accuracy: 0.9647 - val_loss: 0.0577 - val_accuracy: 0.9855\n",
      "Epoch 3/15\n",
      "422/422 [==============================] - 16s 39ms/step - loss: 0.0871 - accuracy: 0.9738 - val_loss: 0.0507 - val_accuracy: 0.9867\n",
      "Epoch 4/15\n",
      "422/422 [==============================] - 16s 38ms/step - loss: 0.0743 - accuracy: 0.9767 - val_loss: 0.0433 - val_accuracy: 0.9883\n",
      "Epoch 5/15\n",
      "422/422 [==============================] - 16s 38ms/step - loss: 0.0627 - accuracy: 0.9809 - val_loss: 0.0427 - val_accuracy: 0.9877\n",
      "Epoch 6/15\n",
      "422/422 [==============================] - 16s 38ms/step - loss: 0.0592 - accuracy: 0.9820 - val_loss: 0.0348 - val_accuracy: 0.9908\n",
      "Epoch 7/15\n",
      "422/422 [==============================] - 16s 37ms/step - loss: 0.0536 - accuracy: 0.9838 - val_loss: 0.0354 - val_accuracy: 0.9908\n",
      "Epoch 8/15\n",
      "422/422 [==============================] - 16s 38ms/step - loss: 0.0480 - accuracy: 0.9848 - val_loss: 0.0342 - val_accuracy: 0.9908\n",
      "Epoch 9/15\n",
      "422/422 [==============================] - 16s 38ms/step - loss: 0.0460 - accuracy: 0.9857 - val_loss: 0.0315 - val_accuracy: 0.9912\n",
      "Epoch 10/15\n",
      "422/422 [==============================] - 16s 38ms/step - loss: 0.0443 - accuracy: 0.9860 - val_loss: 0.0279 - val_accuracy: 0.9923\n",
      "Epoch 11/15\n",
      "422/422 [==============================] - 16s 38ms/step - loss: 0.0416 - accuracy: 0.9865 - val_loss: 0.0314 - val_accuracy: 0.9920\n",
      "Epoch 12/15\n",
      "422/422 [==============================] - 16s 38ms/step - loss: 0.0397 - accuracy: 0.9866 - val_loss: 0.0284 - val_accuracy: 0.9923\n",
      "Epoch 13/15\n",
      "422/422 [==============================] - 16s 38ms/step - loss: 0.0372 - accuracy: 0.9884 - val_loss: 0.0307 - val_accuracy: 0.9927\n",
      "Epoch 14/15\n",
      "422/422 [==============================] - 16s 38ms/step - loss: 0.0365 - accuracy: 0.9882 - val_loss: 0.0302 - val_accuracy: 0.9920\n",
      "Epoch 15/15\n",
      "422/422 [==============================] - 16s 38ms/step - loss: 0.0331 - accuracy: 0.9891 - val_loss: 0.0309 - val_accuracy: 0.9917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 18:39:54.085673: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwm3_2595/model/data/model/assets\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 15\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "mlflow.keras.log_model(model, artifact_path=\"keras-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.utils.environment import _mlflow_conda_env\n",
    "import tensorflow as tf\n",
    "import cloudpickle\n",
    "\n",
    "conda_env = _mlflow_conda_env(\n",
    "    additional_conda_deps=[\n",
    "        \"tensorflow=={}\".format(tf.__version__),\n",
    "    ],\n",
    "    additional_pip_deps=[\n",
    "        \"cloudpickle=={}\".format(cloudpickle.__version__),\n",
    "        \"mlflow=={}\".format(mlflow.__version__),\n",
    "    ])\n",
    "\n",
    "class KerasMnistCNN(mlflow.pyfunc.PythonModel):\n",
    "\n",
    "    def load_context(self, context):\n",
    "        import tensorflow as tf\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            K.set_learning_phase(0)\n",
    "            self.model = mlflow.keras.load_model(context.artifacts[\"keras-model\"])\n",
    "\n",
    "    def predict(self, context, input_df):\n",
    "        with self.graph.as_default():\n",
    "            return self.model.predict(input_df.values.reshape(-1, 28, 28, 1))\n",
    "\n",
    "mlflow.pyfunc.log_model(\n",
    "    artifact_path=\"keras-pyfunc\",\n",
    "    python_model=KerasMnistCNN(),\n",
    "    artifacts={\n",
    "        \"keras-model\": mlflow.get_artifact_uri(\"keras-model\")\n",
    "    },\n",
    "    conda_env=conda_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deploying the model\n",
    "The above code logs a model in the experiments tab. For more info please refer [here](https://rocketml.gitbook.io/rocketml-user-guide/experiments). After deploying the model, we can obtain the model url for performing query as shown below.\n",
    "\n",
    "## 5. Query from the server\n",
    "\n",
    "There are two methods to perform query... The first is using `requests` library and the other using `curl` shell command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "REST API deployment is in progress -- please try again in a few minutes!\n",
      "400\n",
      "REST API deployment is in progress -- please try again in a few minutes!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"http://127.0.0.1:5011/invocations\"\n",
    "headers = {\"Content-Type\":\"text/csv\"}\n",
    "\n",
    "# First case, run inference on single data point\n",
    "np_array = np.random.rand(1,6).tolist()\n",
    "json_data = json.dumps(np_array)\n",
    "response = requests.post(url,data=json_data,headers=headers)\n",
    "if response.status_code == 200:\n",
    "    output = np.array(json.loads(response.json())).astype(np.float32)\n",
    "    print(output)\n",
    "else:\n",
    "    print(response.status_code)\n",
    "    print(\"REST API deployment is in progress -- please try again in a few minutes!\")\n",
    "\n",
    "# Second case, run inference on multiple data points\n",
    "np_array = np.random.rand(20,6).tolist()\n",
    "json_data = json.dumps(np_array)\n",
    "response = requests.post(url,data=json_data,headers=headers)\n",
    "if response.status_code == 200:\n",
    "    output = np.array(json.loads(response.json())).astype(np.float32)\n",
    "    print(output)\n",
    "else:\n",
    "    print(response.status_code)\n",
    "    print(\"REST API deployment is in progress -- please try again in a few minutes!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"error_code\": \"BAD_REQUEST\", \"message\": \"Encountered an unexpected error while evaluating the model. Verify that the serialized input Dataframe is compatible with the model for inference.\", \"stack_trace\": \"Traceback (most recent call last):\\n  File \\\"/anaconda/envs/mlflow-0eb65c492db9b60cb18b7df13009a4ce7ffc117b/lib/python3.7/site-packages/mlflow/pyfunc/scoring_server/__init__.py\\\", line 303, in transformation\\n    raw_predictions = model.predict(data)\\n  File \\\"/anaconda/envs/mlflow-0eb65c492db9b60cb18b7df13009a4ce7ffc117b/lib/python3.7/site-packages/mlflow/pyfunc/__init__.py\\\", line 608, in predict\\n    return self._model_impl.predict(data)\\n  File \\\"/anaconda/envs/mlflow-0eb65c492db9b60cb18b7df13009a4ce7ffc117b/lib/python3.7/site-packages/mlflow/keras.py\\\", line 473, in predict\\n    predicted = _predict(data)\\n  File \\\"/anaconda/envs/mlflow-0eb65c492db9b60cb18b7df13009a4ce7ffc117b/lib/python3.7/site-packages/mlflow/keras.py\\\", line 460, in _predict\\n    predicted = pd.DataFrame(self.keras_model.predict(data.values))\\n  File \\\"/anaconda/envs/mlflow-0eb65c492db9b60cb18b7df13009a4ce7ffc117b/lib/python3.7/site-packages/keras/utils/traceback_utils.py\\\", line 67, in error_handler\\n    raise e.with_traceback(filtered_tb) from None\\n  File \\\"/anaconda/envs/mlflow-0eb65c492db9b60cb18b7df13009a4ce7ffc117b/lib/python3.7/site-packages/keras/engine/training.py\\\", line 1804, in predict\\n    raise ValueError('Unexpected result of `predict_function` '\\nValueError: Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.\\n\"}"
     ]
    }
   ],
   "source": [
    "!curl http://127.0.0.1:5011/invocations -H 'Content-Type:text/csv' -d '[[0.6499166977064089, 0.17579454262114602, 0.2688911143313131, 0.7146591854799202, 0.6497433572112488, 0.7723469203958951]]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/mlflow-0eb65c492db9b60cb18b7df13009a4ce7ffc117b/lib/python3.7/site-packages/mlflow/pyfunc/scoring_server/__init__.py\", line 303, in transformation\n",
      "    raw_predictions = model.predict(data)\n",
      "  File \"/anaconda/envs/mlflow-0eb65c492db9b60cb18b7df13009a4ce7ffc117b/lib/python3.7/site-packages/mlflow/pyfunc/__init__.py\", line 608, in predict\n",
      "    return self._model_impl.predict(data)\n",
      "  File \"/anaconda/envs/mlflow-0eb65c492db9b60cb18b7df13009a4ce7ffc117b/lib/python3.7/site-packages/mlflow/keras.py\", line 473, in predict\n",
      "    predicted = _predict(data)\n",
      "  File \"/anaconda/envs/mlflow-0eb65c492db9b60cb18b7df13009a4ce7ffc117b/lib/python3.7/site-packages/mlflow/keras.py\", line 460, in _predict\n",
      "    predicted = pd.DataFrame(self.keras_model.predict(data.values))\n",
      "  File \"/anaconda/envs/mlflow-0eb65c492db9b60cb18b7df13009a4ce7ffc117b/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/anaconda/envs/mlflow-0eb65c492db9b60cb18b7df13009a4ce7ffc117b/lib/python3.7/site-packages/keras/engine/training.py\", line 1804, in predict\n",
      "    raise ValueError('Unexpected result of `predict_function` '\n",
      "ValueError: Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Traceback (most recent call last):\\n  File \\\"/anaconda/envs/mlflow-0eb65c492db9b60cb18b7df13009a4ce7ffc117b/lib/python3.7/site-packages/mlflow/pyfunc/scoring_server/__init__.py\\\", line 303, in transformation\\n    raw_predictions = model.predict(data)\\n  File \\\"/anaconda/envs/mlflow-0eb65c492db9b60cb18b7df13009a4ce7ffc117b/lib/python3.7/site-packages/mlflow/pyfunc/__init__.py\\\", line 608, in predict\\n    return self._model_impl.predict(data)\\n  File \\\"/anaconda/envs/mlflow-0eb65c492db9b60cb18b7df13009a4ce7ffc117b/lib/python3.7/site-packages/mlflow/keras.py\\\", line 473, in predict\\n    predicted = _predict(data)\\n  File \\\"/anaconda/envs/mlflow-0eb65c492db9b60cb18b7df13009a4ce7ffc117b/lib/python3.7/site-packages/mlflow/keras.py\\\", line 460, in _predict\\n    predicted = pd.DataFrame(self.keras_model.predict(data.values))\\n  File \\\"/anaconda/envs/mlflow-0eb65c492db9b60cb18b7df13009a4ce7ffc117b/lib/python3.7/site-packages/keras/utils/traceback_utils.py\\\", line 67, in error_handler\\n    raise e.with_traceback(filtered_tb) from None\\n  File \\\"/anaconda/envs/mlflow-0eb65c492db9b60cb18b7df13009a4ce7ffc117b/lib/python3.7/site-packages/keras/engine/training.py\\\", line 1804, in predict\\n    raise ValueError('Unexpected result of `predict_function` '\\nValueError: Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
