{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutions based FE loss function implementation\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "In this workbook, we cover the usage of DiffNets to solve Poisson's Equation. The Poisson equation for the scalar field $u({\\bf x})$ can be written as\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "-\\nabla \\cdot (\\nu({\\bf x}) \\nabla u({\\bf x})) &= 0 \\ \\textrm{ in } D\\\\\n",
    "u &= 0 \\ \\textrm{ on } \\partial D\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where, the domain $D = [0,1]^2$ is the unit square; ${\\bf x} = (x,y)$ represents the independent variables and $\\nu({\\bf x})$ represents the *diffusivity* (or *permeability*) of the medium. In this example, $\\nu = \\nu({\\bf x}, \\omega)$ where $\\omega$ is a parameter that can be randomly chosen from a parameter space $\\Omega$. Thus, by varying $\\omega$, we can obtain different $\\nu$ fields, each of which then renders a different solution to the above Poisson's equation. This means, every time a different $\\omega$ is chosen, the solution needs to be obtained by solving the equation. But using DiffNet, we can train a model offline one time and learn the correct mapping so that we do not need to solve the equation again as long as $\\omega$ is chosen from the same parameter space $\\Omega$. Therefore, we wish to train a DiffNet $G_{nn}$ such that it is able to construct the correct mapping between the input space of $S^d$ and the space of the solutions $U^d$.\n",
    "\n",
    "For the purpose of this tutorial, it suffices to assume that the logarithm of $\\nu({\\bf x}; \\omega)$ can be expressed in summation form as follows:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\ln(\\nu({\\bf x}; \\omega)) &= \\sum_{i=1}^{m}\\omega_i \\xi_i(x)\\eta_i(y)\\\\\n",
    "\\text{or},\\  \\nu({\\bf x}; \\omega) &= \\exp \\Big(\\sum_{i=1}^{m}\\omega_i \\xi_i(x)\\eta_i(y)\\Big)\n",
    "\\end{align}\n",
    "$$\n",
    "where $\\xi$ and $\\eta$ are known functions of $x$ and $y$ respectively. See Sec. 2.2.1 of [this paper](https://arxiv.org/abs/2104.14538) for more details. We choose $m=6$ for this example and assume that each $\\omega_i$ is chosen from $[-3,3]$ interval randomly. Thus, $\\omega\\in\\Omega = [-3,3]^6$.\n",
    "\n",
    "## 2. DiffNet\n",
    "A trained DiffNet can take a full field of diffusivity (or forcing) and map it to the full field solution. For example, in the below schematic, we see a trained DiffNet $G_{nn}$ takes a matrix $S^d$ (numerical version of $\\nu({\\bf x})$) as input and map it to another matrix $U^d$ (approximated version of $u({\\bf x}))$:\n",
    "![](https://raw.githubusercontent.com/rocketmlhq/sciml/main/05_DiffNets/xdiffnet-scheme.png)\n",
    "Both $S^d$ and $U^d$ are matrices (or images) of the same size ($6\\times 6$ or, $5\\times 5$ \"finite elements\"). The neural network $G_{nn}$ can be thought of as a having a UNet architecture as below:\n",
    "![](https://raw.githubusercontent.com/rocketmlhq/sciml/main/05_DiffNets/UNetArch.png)\n",
    "\n",
    "Suppose the network parameters are given by $\\theta$. Then, given such discretized representations of $S^d$ and $U^d$, DiffNet solves the Poisson's equation by minimizing the integral loss function given by:\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{N_s}\\sum_{j=1}^{N_s} \\int \\nu_j({\\bf x}; \\omega)|\\nabla u_j({\\bf x}, \\theta)|^2 d{\\bf x},\n",
    "$$\n",
    "where $u_j = G_{nn}(\\nu_j, \\theta)$, i.e., the solution corresponding to the $j^{th}$ sample of diffusivity.\n",
    "\n",
    "The solution is then given by:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\theta^* &= \\arg\\min J(\\theta),\\\\\n",
    "u &= G_{nn}(\\nu, \\theta^*).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We minimize the loss function $J(\\theta)$ using Adam optimizer.\n",
    "\n",
    "The DiffNet library provides in-built capability to approximate full field solutions and Lagrangian basis functions as convolution kernels along with evaluations on Gauss quadrature points. To use these features for solving the Poisson's equation, we need to implement two classes:\n",
    "1. A dataset class `KLSum` (derived from `torch.utils.Dataset`): to implement the diffusivity, forcing and the boundary conditions.\n",
    "2. An equation class `Poisson` (derived from `DiffNet.DiffNetFEM`): to implement the loss function, training step, optimizer configuration, query step etc.\n",
    "\n",
    "## 3. Imports\n",
    "We begin with few imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "# matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    # 'font.family': 'serif',\n",
    "    'font.size':12,\n",
    "})\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "seed_everything(42)\n",
    "\n",
    "import DiffNet\n",
    "from DiffNet.networks.wgan_old import GoodGenerator\n",
    "from DiffNet.networks.autoencoders import AE\n",
    "from DiffNet.DiffNetFEM import DiffNet2DFEM\n",
    "from DiffNet.datasets.parametric.klsum import KLSumStochastic\n",
    "from DiffNet.datasets.single_instances.klsum import Dataset\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset class\n",
    "Suppose we discretize the 2D domain into regularly spaced $N\\times N$ grid points (i.e., $(N-1)\\times(N-1)$ finite elements.\n",
    "\n",
    "The `KLSum` class holds the given \"input data\" of the equation, i.e., the diffusivity ($\\nu$) and the boundary conditions ($u_{\\partial D}$). The important thing to note here is that, since DiffNet is based on full-field calculations, all three of these data need to be stored in tensor format. Specifically, since the current equation is defined on a 2D square domain, we store each of $\\nu$, $f$ and $u_{\\partial D}$ in 2D matrices of size $N\\times N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils import data\n",
    "from DiffNet.gen_input_calc import generate_diffusivity_tensor\n",
    "\n",
    "\n",
    "class KLSum(data.Dataset):\n",
    "    'PyTorch dataset for sampling coefficients'\n",
    "    def __init__(self, domain_size=64, kl_terms=6, filename='', coeff_array=[]):\n",
    "        \"\"\"\n",
    "        Initialization\n",
    "        \"\"\"\n",
    "        if filename != '':\n",
    "            self.coeffs = np.load(filename)\n",
    "        else:\n",
    "            if coeff_array != []:\n",
    "                self.coeffs = coeff_array\n",
    "            else:\n",
    "                raise ValueError(\"Either filename or an array must be provided\")\n",
    "        self.domain_size = domain_size\n",
    "        self.kl_terms = kl_terms\n",
    "        self.dataset = []\n",
    "        \n",
    "        print('loading dataset')\n",
    "        for coeff in tqdm(self.coeffs[:100]):\n",
    "            domain = generate_diffusivity_tensor(coeff, output_size=self.domain_size, n_sum_nu=kl_terms).squeeze()\n",
    "            # bc1 will be source, u will be set to 1 at these locations\n",
    "            bc1 = np.zeros_like(domain)\n",
    "            bc1[:,0] = 1\n",
    "\n",
    "            # bc2 will be sink, u will be set to 0 at these locations\n",
    "            bc2 = np.zeros_like(domain)\n",
    "            bc2[:,-1] = 1\n",
    "\n",
    "            self.dataset.append(np.array([domain,bc1,bc2]))\n",
    "        self.dataset = np.array(self.dataset)\n",
    "        self.n_samples = self.dataset.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        inputs = self.dataset[index]\n",
    "        forcing = np.zeros_like(self.dataset[index][0])\n",
    "        return torch.FloatTensor(inputs), torch.FloatTensor(forcing).unsqueeze(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training data\n",
    "As discussed above, the formula for calculating $\\nu$ for a particular $\\omega$ is known to us. So, to create the training dataset of multiple $\\nu$, we essentially need to create a training dataset of multiple $\\omega$ chosen from the 6-dimensional space $\\Omega$ and thereafter calculate $\\nu$ at each of those $\\omega$. Before defining the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-11-15 03:59:35--  https://github.com/rocketmlhq/sciml/raw/main/05_DiffNets/sobol_6d.npy\n",
      "Resolving github.com (github.com)... 140.82.113.3\n",
      "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/rocketmlhq/sciml/main/05_DiffNets/sobol_6d.npy [following]\n",
      "--2021-11-15 03:59:35--  https://raw.githubusercontent.com/rocketmlhq/sciml/main/05_DiffNets/sobol_6d.npy\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3145856 (3.0M) [application/octet-stream]\n",
      "Saving to: ‘sobol_6d.npy’\n",
      "\n",
      "sobol_6d.npy        100%[===================>]   3.00M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2021-11-15 03:59:36 (25.3 MB/s) - ‘sobol_6d.npy’ saved [3145856/3145856]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/rocketmlhq/sciml/raw/main/05_DiffNets/sobol_6d.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Equation class\n",
    "\n",
    "Now we need to define the equation class `Poisson` that inherits the `DiffNet.DiffNetFEM` class which in turn inherits the `LightningModule` class from `pytorch_lightning.core`. The main purpose of `Poisson` is to implement the training step and the loss function along with optimizer configurations (if necessary). Let us discuss them one by one:\n",
    "* `training_step`: this function will be called by `PytorchLightning` every training step with an input `batch`. This `batch` represents the data for a minibatch and is obtained by `PytorchLightning` by calling the `__getitem__` function in the `DataRectangle` class.\n",
    "* `loss(u, I, f)`: the loss function can be implemented in many ways, but essentially takes the data of the equation and calculates the loss value. In this implementation `loss` takes the currently predicted field `u` and the other inputs (BC, nu, f). Inside this function, we evaluate the integral $J(u) = \\frac{1}{N_s}\\sum_{i=1}^{N_s} \\int \\nu_i|\\nabla u_i|^2 d{\\bf x}$. This is an important step and is done as follows:\n",
    "    * Extract `nu` and `bc` from `imputs_tensor`\n",
    "    * Apply the boundary conditions on `u` using the boundary masks (i.e., `bc1` and `bc2` that contain zeros in the interior points, and ones on the boundary points.\n",
    "    * Now we need to evaluate the values in the integrand at the Gauss quadrature points. Given any field `g` on the grid points, we can evaluate `g` on **_all_** the Gauss quadrature points in $D$, by calling `g_GP = self.gauss_pt_evaluation(g)`. The derivatives of `g` can be evaluated on the Gauss points directly by `g_x_GP = self.gauss_pt_evaluation_der_x(g)` and `g_y_GP = self.gauss_pt_evaluation_der_y(g)` for the $x$ and $y$ derivative respectively.\n",
    "    * Once all the integration values are evaluated on the quadrature points, the next step is to simply write down the integration using the quadrature data, exactly as it appears in the loss formula.\n",
    "* Along with the above two functions, some other auxiliary functions can be added to this class as needed, e.g., `do_query`, `plot_contours`, `on_epoch_end` etc.\n",
    "* `on_epoch_end` is called by `PytorchLightning` at the end of each epoch during training. We can plot the current `u` vlaue at the end of each epoch by implementing this function accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Poisson(DiffNet2DFEM):\n",
    "    \"\"\"docstring for Poisson\"\"\"\n",
    "    def __init__(self, network, dataset, **kwargs):\n",
    "        super(Poisson, self).__init__(network, dataset, **kwargs)\n",
    "\n",
    "    def loss(self, u, inputs_tensor, forcing_tensor):\n",
    "\n",
    "        f = forcing_tensor # renaming variable\n",
    "        \n",
    "        # extract diffusivity and boundary conditions here\n",
    "        nu = inputs_tensor[:,0:1,:,:]\n",
    "        bc1 = inputs_tensor[:,1:2,:,:]\n",
    "        bc2 = inputs_tensor[:,2:3,:,:]\n",
    "\n",
    "        # apply boundary conditions\n",
    "        u = torch.where(bc1>0.5,1.0+u*0.0,u)\n",
    "        u = torch.where(bc2>0.5,u*0.0,u)\n",
    "\n",
    "\n",
    "        nu_gp = self.gauss_pt_evaluation(nu)\n",
    "        f_gp = self.gauss_pt_evaluation(f)\n",
    "        u_gp = self.gauss_pt_evaluation(u)\n",
    "        u_x_gp = self.gauss_pt_evaluation_der_x(u)\n",
    "        u_y_gp = self.gauss_pt_evaluation_der_y(u)\n",
    "\n",
    "        transformation_jacobian = self.gpw.unsqueeze(-1).unsqueeze(-1).unsqueeze(0).type_as(nu_gp)\n",
    "        res_elmwise = transformation_jacobian * (nu_gp * (u_x_gp**2 + u_y_gp**2) - (u_gp * f_gp))\n",
    "        res_elmwise = torch.sum(res_elmwise, 1) \n",
    "\n",
    "        # transformation_jacobian = (0.5 * self.h)**2 * self.gpw.unsqueeze(-1).unsqueeze(-1).unsqueeze(0).type_as(nu_gp)\n",
    "        # res_elmwise = 0.5 * transformation_jacobian * (nu_gp * (u_x_gp**2 + u_y_gp**2) - (u_gp * f_gp))\n",
    "        # res_elmwise = torch.sum(res_elmwise, 1) \n",
    "\n",
    "        loss = torch.mean(res_elmwise)\n",
    "        return loss\n",
    "\n",
    "    def forward(self, batch):\n",
    "        inputs_tensor, forcing_tensor = batch\n",
    "        u = self.network(inputs_tensor[:,0:1,:,:])\n",
    "        return u, inputs_tensor, forcing_tensor\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        u, inputs_tensor, forcing_tensor = self.forward(batch)\n",
    "        loss_val = self.loss(u, inputs_tensor, forcing_tensor).mean()\n",
    "        return {\"loss\": loss_val}\n",
    "\n",
    "    def training_step_end(self, training_step_outputs):\n",
    "        loss = training_step_outputs[\"loss\"]\n",
    "        self.log('PDE_loss', loss.item())\n",
    "        self.log('loss', loss.item())\n",
    "        return training_step_outputs\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        lr = self.learning_rate\n",
    "        # opts = [torch.optim.LBFGS(self.network.parameters(), lr=lr, max_iter=5)]\n",
    "        opts = [torch.optim.Adam(self.network.parameters(), lr=lr)]\n",
    "        # schd = []\n",
    "        schd = [torch.optim.lr_scheduler.MultiStepLR(opts[0], milestones=[10,15,30], gamma=0.1)]\n",
    "        return opts, schd\n",
    "    \n",
    "    def do_query(self, inputs, forcing):\n",
    "        u, inputs_tensor, forcing_tensor = self.forward((inputs.type_as(next(self.network.parameters())), \n",
    "                                                         forcing.type_as(next(self.network.parameters()))))\n",
    "        \n",
    "        f = forcing_tensor.squeeze().detach().cpu() # renaming variable\n",
    "        \n",
    "        # extract diffusivity and boundary conditions here\n",
    "        nu = inputs_tensor[:,0:1,:,:]\n",
    "        bc1 = inputs_tensor[:,1:2,:,:]\n",
    "        bc2 = inputs_tensor[:,2:3,:,:]        \n",
    "        # process diffusivity\n",
    "        k = nu.squeeze().detach().cpu()\n",
    "\n",
    "        # apply boundary conditions\n",
    "        u = u[:,0:1,:,:]\n",
    "        u = torch.where(bc1>0.5,1.0+u*0.0,u)\n",
    "        u = torch.where(bc2>0.5,u*0.0,u)\n",
    "        u = u.squeeze().detach().cpu()\n",
    "        \n",
    "        return u, k, f\n",
    "    \n",
    "    def plot_contours(self,k,u):\n",
    "        num_sample = k.shape[0]\n",
    "        plt_num_row = k.shape[0]\n",
    "        plt_num_col = 2\n",
    "        fig, axs = plt.subplots(plt_num_row, plt_num_col, figsize=(4*plt_num_col,2*plt_num_row),\n",
    "                            subplot_kw={'aspect': 'auto'}, sharex=True, sharey=True, squeeze=True)\n",
    "        for ax_row in axs:\n",
    "            for ax in ax_row:\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])              \n",
    "        \n",
    "        # print(np.linalg.norm(diff.flatten())/self.domain_size)\n",
    "#         im = axs[0].imshow(k,cmap='jet')\n",
    "#         fig.colorbar(im, ax=axs[1]); axs[1].set_title(r'$\\nu$')\n",
    "#         im = axs[1].imshow(u,cmap='jet', vmin=0.0, vmax=1.0)\n",
    "#         fig.colorbar(im, ax=axs[2]); axs[2].set_title(r'$u_{\\theta}$')\n",
    "#         plt.show()\n",
    "        \n",
    "        for idx in range(num_sample):\n",
    "            im0 = axs[idx][0].imshow(k[idx,:,:],cmap='jet')\n",
    "            fig.colorbar(im0, ax=axs[idx,0]); axs[idx,0].set_title(r'$\\nu$')\n",
    "            im1 = axs[idx][1].imshow(u[idx,:,:],cmap='jet')\n",
    "            fig.colorbar(im1, ax=axs[idx,1]); axs[idx,1].set_title(r'$u_{\\theta}$')  \n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        num_query = 6\n",
    "        plt_num_row = num_query\n",
    "        plt_num_col = 2\n",
    "        fig, axs = plt.subplots(plt_num_row, plt_num_col, figsize=(2*plt_num_col,1.2*plt_num_row),\n",
    "                            subplot_kw={'aspect': 'auto'}, sharex=True, sharey=True, squeeze=True)\n",
    "        for ax_row in axs:\n",
    "            for ax in ax_row:\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "        \n",
    "        self.network.eval()\n",
    "        inputs, forcing = self.dataset[0:num_query]\n",
    "        forcing = forcing.repeat(num_query,1,1,1)\n",
    "\n",
    "        ub, inputs_tensor, forcing_tensor = self.forward((inputs.type_as(next(self.network.parameters())), forcing.type_as(next(self.network.parameters()))))\n",
    "        \n",
    "        loss = self.loss(ub, inputs_tensor, forcing_tensor[:,0:1,:,:])\n",
    "\n",
    "        for idx in range(num_query):\n",
    "            f = forcing_tensor # renaming variable\n",
    "            \n",
    "            # extract diffusivity and boundary conditions here\n",
    "            nu = inputs_tensor[idx,0:1,:,:]\n",
    "            u = ub[idx,0:1,:,:]\n",
    "            bc1 = inputs_tensor[idx,1:2,:,:]\n",
    "            bc2 = inputs_tensor[idx,2:3,:,:]\n",
    "\n",
    "            # apply boundary conditions\n",
    "            u = torch.where(bc1>0.5,1.0+u*0.0,u)\n",
    "            u = torch.where(bc2>0.5,u*0.0,u)\n",
    "\n",
    "            k = nu.squeeze().detach().cpu()\n",
    "            u = u.squeeze().detach().cpu()\n",
    "\n",
    "            im0 = axs[idx][0].imshow(k,cmap='jet')\n",
    "            fig.colorbar(im0, ax=axs[idx,0])\n",
    "            im1 = axs[idx][1].imshow(u,cmap='jet')\n",
    "            fig.colorbar(im1, ax=axs[idx,1])  \n",
    "        plt.savefig(os.path.join(self.logger[0].log_dir, 'contour_' + str(self.current_epoch) + '.png'))\n",
    "        self.logger[0].experiment.add_figure('Contour Plots', fig, self.current_epoch)\n",
    "        plt.close('all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 7. MLflow for experiment tracking and model deployment\n",
    "\n",
    "MLflow is an open source platform for managing the end-to-end machine learning lifecycle. It tackles four primary functions:\n",
    "\n",
    "- Tracking experiments to record and compare parameters and results (MLflow Tracking).\n",
    "- Managing and deploying models from a variety of ML libraries to a variety of model serving and inference platforms (MLflow Models).\n",
    "- Providing a central model store to collaboratively manage the full lifecycle of an MLflow Model, including model versioning, stage transitions, and annotations (MLflow Model Registry).\n",
    "\n",
    "More information [here](https://www.mlflow.org/docs/latest/index.html#)\n",
    "\n",
    "\n",
    "\n",
    "![image.png](https://www.mlflow.org/docs/latest/_images/scenario_4.png)\n",
    "\n",
    "- localhost maps to the server on which the current notebook is running\n",
    "\n",
    "- Tracking server maps to the server at environment variable `TRACKING_URL` that can be printed using `os.environ.get(\"TRACKING_URL\")`\n",
    "\n",
    "- Create an mlflow client that communicates with the tracking server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow import pyfunc\n",
    "\n",
    "# Setting a tracking uri to log the mlflow logs in a particular location tracked by \n",
    "from mlflow.tracking import MlflowClient\n",
    "tracking_uri = os.environ.get(\"TRACKING_URL\")\n",
    "client = MlflowClient(tracking_uri=tracking_uri)\n",
    "mlflow.set_tracking_uri(tracking_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Create an experiment in mlflow database using mlflow client\n",
    "\n",
    "- Get the list of all the experiments (Click on **Experiments** tab on the sidebar to see the list)\n",
    "- Create a new experiment named *numpy_deployment* if it doesn't exist\n",
    "- Set *numpy_deployment* as the new experiment under which different **runs** are tracked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MLflow Entity Hierarchy\n",
    "\n",
    "- Experiment 1\n",
    "    - Run 1\n",
    "        - Parameters\n",
    "        - Metrics\n",
    "        - Artifacts\n",
    "            - Folder 1\n",
    "                - File 1\n",
    "                - File 2\n",
    "            - Folder 2 \n",
    "    - Run 2\n",
    "    - Run 3\n",
    "\n",
    "- Experiment 2\n",
    "- Experiment 3        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a tracking project experiment name to keep the experiments organized\n",
    "experiments = client.list_experiments()\n",
    "experiment_names = []\n",
    "for exp in experiments:\n",
    "    experiment_names.append(exp.name)\n",
    "experiment_name = \"diffnet_deployment\"\n",
    "if experiment_name not in experiment_names:\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "mlflow.set_experiment(experiment_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Python Class for inference\n",
    "\n",
    "- ModelWrapper is derived from mlflow.pyfunc.PythonModel [more info](https://www.mlflow.org/docs/latest/python_api/mlflow.pyfunc.html)\n",
    "- load_context() member function is used to load the model. In this case, it loads a keras trained model which can be loaded.\n",
    "- predict member function takes a numpy array as input and outputs another numpy array\n",
    "- An object of this class will be saved as a pickle file in blob storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Wrapper that takes \n",
    "class ModelWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def load_context(self,context):\n",
    "        import numpy as np\n",
    "        import torch\n",
    "        import os\n",
    "        model = torch.load(os.path.join(context.artifacts[\"model_path\"], 'network.pt'))\n",
    "        self.model = model\n",
    "        print(\"Model initialized\")\n",
    "    \n",
    "    def predict(self, context, model_input):\n",
    "        import numpy as np\n",
    "        import json\n",
    "        import torch\n",
    "        print(model_input)\n",
    "        print(model_input.columns)\n",
    "        print(model_input.columns.values)\n",
    "        json_txt = \", \".join(model_input.columns)\n",
    "        print(json_txt)\n",
    "        data_list = json.loads(json_txt)\n",
    "        inputs = np.array(data_list)\n",
    "        if len(inputs.shape) == 4:\n",
    "            print('batch inference')\n",
    "            predictions = self.model(torch.from_numpy(inputs)).detach().cpu().numpy().tolist()\n",
    "        elif len(inputs.shape) == 3:\n",
    "            print('single inference')\n",
    "            inputs = inputs.unsqueeze(0)\n",
    "            predictions = self.model(torch.from_numpy(inputs)).detach().cpu().numpy().tolist()\n",
    "        elif len(inputs.shape) == 2:\n",
    "            print('single inference squeeze')\n",
    "            inputs = inputs.unsqueeze(0).unsqueeze(0)\n",
    "            predictions = self.model(torch.from_numpy(inputs)).detach().cpu().numpy().tolist()            \n",
    "        else:\n",
    "            raise ValueError('invalid input shape')\n",
    "        return json.dumps(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_epochs =  1\n",
      "loading dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1350.61it/s]\n",
      "Missing logger folder: ./klsum_32\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "kl_terms = 6\n",
    "domain_size = 32\n",
    "LR = 1e-3\n",
    "batch_size = 128\n",
    "sample_size = 65536\n",
    "sobol_file = 'sobol_'+str(kl_terms)+'d.npy'\n",
    "max_epochs = 1\n",
    "print(\"Max_epochs = \", max_epochs)\n",
    "\n",
    "dataset = KLSum(domain_size=domain_size, kl_terms=kl_terms, filename=sobol_file)\n",
    "network = AE(in_channels=1, out_channels=1, dims=16, n_downsample=2)\n",
    "basecase = Poisson(network, dataset, batch_size=batch_size, domain_size=domain_size, learning_rate=LR)\n",
    "\n",
    "# ------------------------\n",
    "# 1 INIT TRAINER\n",
    "# ------------------------\n",
    "logger = pl.loggers.TensorBoardLogger('.', name=\"klsum_\"+str(domain_size))\n",
    "csv_logger = pl.loggers.CSVLogger(logger.save_dir, name=logger.name, version=logger.version)\n",
    "\n",
    "checkpoint = pl.callbacks.model_checkpoint.ModelCheckpoint(monitor='loss',\n",
    "    dirpath=logger.log_dir, filename='{epoch}-{step}',\n",
    "    mode='min', save_last=True)\n",
    "\n",
    "trainer = Trainer(callbacks=[checkpoint],\n",
    "    checkpoint_callback=True, logger=[logger,csv_logger],\n",
    "    max_epochs=max_epochs, deterministic=True, profiler='simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-15 03:59:39.145187: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-15 03:59:39.145225: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "\n",
      "  | Name      | Type          | Params\n",
      "--------------------------------------------\n",
      "0 | network   | AE            | 264 K \n",
      "1 | N_gp      | ParameterList | 16    \n",
      "2 | dN_x_gp   | ParameterList | 16    \n",
      "3 | dN_y_gp   | ParameterList | 16    \n",
      "4 | d2N_x_gp  | ParameterList | 16    \n",
      "5 | d2N_y_gp  | ParameterList | 16    \n",
      "6 | d2N_xy_gp | ParameterList | 16    \n",
      "--------------------------------------------\n",
      "264 K     Trainable params\n",
      "96        Non-trainable params\n",
      "264 K     Total params\n",
      "1.058     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c534a64140b54a01b53ed35c82932745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  12.254         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  9.2401         \t|1              \t|  9.2401         \t|  75.406         \t|\n",
      "run_training_batch                 \t|  7.2714         \t|1              \t|  7.2714         \t|  59.34          \t|\n",
      "optimizer_step_with_closure_0      \t|  7.2705         \t|1              \t|  7.2705         \t|  59.333         \t|\n",
      "training_step_and_backward         \t|  7.0699         \t|1              \t|  7.0699         \t|  57.696         \t|\n",
      "backward                           \t|  4.7977         \t|1              \t|  4.7977         \t|  39.153         \t|\n",
      "model_forward                      \t|  2.272          \t|1              \t|  2.272          \t|  18.541         \t|\n",
      "training_step                      \t|  2.2672         \t|1              \t|  2.2672         \t|  18.502         \t|\n",
      "on_epoch_end                       \t|  1.6928         \t|1              \t|  1.6928         \t|  13.814         \t|\n",
      "on_train_epoch_end                 \t|  0.26154        \t|1              \t|  0.26154        \t|  2.1343         \t|\n",
      "on_train_end                       \t|  0.10932        \t|1              \t|  0.10932        \t|  0.8921         \t|\n",
      "on_train_start                     \t|  0.019421       \t|1              \t|  0.019421       \t|  0.15849        \t|\n",
      "on_pretrain_routine_start          \t|  0.013191       \t|1              \t|  0.013191       \t|  0.10764        \t|\n",
      "get_train_batch                    \t|  0.0032501      \t|2              \t|  0.0065002      \t|  0.053047       \t|\n",
      "fetch_next_train_batch             \t|  0.0032293      \t|2              \t|  0.0064586      \t|  0.052707       \t|\n",
      "training_step_end                  \t|  0.0045257      \t|1              \t|  0.0045257      \t|  0.036933       \t|\n",
      "on_train_batch_end                 \t|  0.0040532      \t|1              \t|  0.0040532      \t|  0.033077       \t|\n",
      "on_train_epoch_start               \t|  0.001356       \t|1              \t|  0.001356       \t|  0.011066       \t|\n",
      "configure_optimizers               \t|  0.00036563     \t|1              \t|  0.00036563     \t|  0.0029839      \t|\n",
      "zero_grad                          \t|  0.00017001     \t|1              \t|  0.00017001     \t|  0.0013875      \t|\n",
      "on_after_backward                  \t|  0.00012301     \t|1              \t|  0.00012301     \t|  0.0010039      \t|\n",
      "train_dataloader                   \t|  0.00012271     \t|1              \t|  0.00012271     \t|  0.0010014      \t|\n",
      "on_train_batch_start               \t|  0.00011121     \t|1              \t|  0.00011121     \t|  0.00090756     \t|\n",
      "training_batch_to_device           \t|  0.00010561     \t|1              \t|  0.00010561     \t|  0.00086186     \t|\n",
      "on_batch_end                       \t|  2.5802e-05     \t|1              \t|  2.5802e-05     \t|  0.00021056     \t|\n",
      "on_before_zero_grad                \t|  2.4202e-05     \t|1              \t|  2.4202e-05     \t|  0.00019751     \t|\n",
      "on_configure_sharded_model         \t|  2.3102e-05     \t|1              \t|  2.3102e-05     \t|  0.00018853     \t|\n",
      "on_fit_end                         \t|  2.2602e-05     \t|1              \t|  2.2602e-05     \t|  0.00018445     \t|\n",
      "on_fit_start                       \t|  2.2302e-05     \t|1              \t|  2.2302e-05     \t|  0.000182       \t|\n",
      "on_batch_start                     \t|  1.9401e-05     \t|1              \t|  1.9401e-05     \t|  0.00015833     \t|\n",
      "teardown                           \t|  1.9302e-05     \t|1              \t|  1.9302e-05     \t|  0.00015752     \t|\n",
      "on_before_accelerator_backend_setup\t|  1.9201e-05     \t|1              \t|  1.9201e-05     \t|  0.0001567      \t|\n",
      "on_pretrain_routine_end            \t|  1.6302e-05     \t|1              \t|  1.6302e-05     \t|  0.00013304     \t|\n",
      "setup                              \t|  1.5702e-05     \t|1              \t|  1.5702e-05     \t|  0.00012814     \t|\n",
      "on_epoch_start                     \t|  1.4101e-05     \t|1              \t|  1.4101e-05     \t|  0.00011508     \t|\n",
      "on_before_optimizer_step           \t|  1.3101e-05     \t|1              \t|  1.3101e-05     \t|  0.00010691     \t|\n",
      "on_before_backward                 \t|  1.2801e-05     \t|1              \t|  1.2801e-05     \t|  0.00010447     \t|\n",
      "prepare_data                       \t|  9.301e-06      \t|1              \t|  9.301e-06      \t|  7.5903e-05     \t|\n",
      "configure_sharded_model            \t|  7.8e-06        \t|1              \t|  7.8e-06        \t|  6.3654e-05     \t|\n",
      "on_train_dataloader                \t|  5.001e-06      \t|1              \t|  5.001e-06      \t|  4.0812e-05     \t|\n",
      "configure_callbacks                \t|  4.101e-06      \t|1              \t|  4.101e-06      \t|  3.3467e-05     \t|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(basecase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Register a model using mlflow\n",
    "\n",
    "- Log user-defined parameters in a remote database through a remote server\n",
    "- Create a model_wrapper object using ModelWrapper() class in the above cell\n",
    "- Create a default conda environment that need to be installed on the Docker conatiner that serves a REST API\n",
    "- Save the model object as a pickle file and conda environment as artifacts (files) in S3 or Blob Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(basecase.network, os.path.join(logger.log_dir, 'network.pt'))\n",
    "# instantiate the python inference model wrapper for the server\n",
    "model_wrapper = ModelWrapper()\n",
    "\n",
    "\n",
    "# checkpointing and logging the model in mlflow\n",
    "artifact_path = logger.log_dir\n",
    "model_artifacts = {\"model_path\" : artifact_path}\n",
    "\n",
    "#Conda environment\n",
    "env = mlflow.pytorch.get_default_conda_env()\n",
    "\n",
    "## Utility function to add libraries to conda environment\n",
    "def add_libraries_to_conda_env(_conda_env,libraries=[],conda_dependencies=[]):\n",
    "    dependencies = _conda_env[\"dependencies\"]\n",
    "    dependencies = dependencies + conda_dependencies\n",
    "    pip_index = None\n",
    "    for _index,_element in enumerate(dependencies):\n",
    "        if type(_element) == dict:\n",
    "            if \"pip\" in _element.keys():\n",
    "                pip_index = _index\n",
    "                break\n",
    "    dependencies[pip_index][\"pip\"] =  dependencies[pip_index][\"pip\"] + libraries\n",
    "    _conda_env[\"dependencies\"] = dependencies\n",
    "    return _conda_env\n",
    "env = add_libraries_to_conda_env(env,libraries=['git+https://github.com/adityabalu/DiffNet.git'])\n",
    "with mlflow.start_run():\n",
    "    mlflow.pyfunc.log_model(\"diffnet_model\", python_model=model_wrapper, artifacts=model_artifacts, conda_env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 1153.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "REST API deployment is in progress -- please try again in a few minutes!\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15849/2316513183.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mbasecase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_contours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_15849/1653956787.py\u001b[0m in \u001b[0;36mplot_contours\u001b[0;34m(self, k, u)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mim0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'jet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'$\\nu$'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mim1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'jet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x4608 with 64 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "query_array = np.random.rand(5,6) # five samples of size 6\n",
    "dataset = KLSum(domain_size=domain_size, kl_terms=kl_terms, filename='', coeff_array=query_array)\n",
    "# dataset = Dataset('../single_instance/example-coefficients.txt', domain_size=64)\n",
    "\n",
    "inputs, forcing = dataset[0:1]\n",
    "nu = inputs[:,0:1,:,:].numpy()\n",
    "\n",
    "json_data = json.dumps(nu.tolist())\n",
    "\n",
    "################################################################################\n",
    "# *** SET MODEL URL HERE BEFORE RUNNING THIS CELL (instructions above) ***\n",
    "# Example: https://<random_string>.sciml.rocketml.net/invocations\n",
    "url = \"http://127.0.0.1:5000/invocations\"\n",
    "################################################################################\n",
    "\n",
    "if not url:\n",
    "    raise ValueError('Model URL not set! Please read instructions on how to deploy model, set the correct URL, and try again.')\n",
    "\n",
    "headers = {\"Content-Type\":\"text/csv\"}\n",
    "\n",
    "if url:\n",
    "    response = requests.post(url,data=json_data,headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        output = np.array(json.loads(response.json())).astype(np.float32)\n",
    "        print(output)\n",
    "    else:\n",
    "        print(response.status_code)\n",
    "        print(\"REST API deployment is in progress -- please try again in a few minutes!\")\n",
    "else:\n",
    "    print(\"Make sure that the model is in ON state. Copy the Endpoint\")\n",
    "\n",
    "\n",
    "\n",
    "# plot\n",
    "basecase.plot_contours(nu.squeeze(),nu.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error_code': 'BAD_REQUEST',\n",
       " 'message': 'Encountered an unexpected error while evaluating the model. Verify that the serialized input Dataframe is compatible with the model for inference.',\n",
       " 'stack_trace': 'Traceback (most recent call last):\\n  File \"/home/ubuntu/.conda/envs/mlflow-9cc60af632363df27dc396a01b531f0e965ba341/lib/python3.7/site-packages/mlflow/pyfunc/scoring_server/__init__.py\", line 303, in transformation\\n    raw_predictions = model.predict(data)\\n  File \"/home/ubuntu/.conda/envs/mlflow-9cc60af632363df27dc396a01b531f0e965ba341/lib/python3.7/site-packages/mlflow/pyfunc/__init__.py\", line 608, in predict\\n    return self._model_impl.predict(data)\\n  File \"/home/ubuntu/.conda/envs/mlflow-9cc60af632363df27dc396a01b531f0e965ba341/lib/python3.7/site-packages/mlflow/pyfunc/model.py\", line 296, in predict\\n    return self.python_model.predict(self.context, model_input)\\n  File \"/tmp/ipykernel_15849/1962923228.py\", line 15, in predict\\nNameError: name \\'model_inputs\\' is not defined\\n'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
