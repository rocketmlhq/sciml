{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "import matplotlib\n",
    "# matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    # 'font.family': 'serif',\n",
    "    'font.size':12,\n",
    "})\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "seed_everything(42)\n",
    "\n",
    "import DiffNet\n",
    "from DiffNet.networks.wgan import GoodNetwork\n",
    "from DiffNet.DiffNetFDM import DiffNetFDM\n",
    "from DiffNet.datasets.single_instances.klsum import Dataset\n",
    "from DiffNet.datasets.single_instances.rectangles import RectangleManufactured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Poisson(DiffNetFDM):\n",
    "    \"\"\"docstring for Poisson\"\"\"\n",
    "    def __init__(self, network, dataset, **kwargs):\n",
    "        super(Poisson, self).__init__(network, dataset, **kwargs)\n",
    "        x = np.linspace(0,1,self.domain_size)\n",
    "        y = np.linspace(0,1,self.domain_size)\n",
    "        xx, yy = np.meshgrid(x,y)\n",
    "        self.u_exact = torch.tensor(np.sin(np.pi*xx)*np.sin(np.pi*yy))\n",
    "\n",
    "        self.h = 1. / (self.domain_size - 1)\n",
    "\n",
    "    def test(self):\n",
    "        x = torch.linspace(0, 1., 64)\n",
    "        y = torch.linspace(0, 1., 64)\n",
    "        xv, yv = torch.meshgrid(x, y)\n",
    "\n",
    "        print(\"x = \", xv)\n",
    "        print(\"y = \", yv)\n",
    "        print(\"sobelx = \", self.sobelx)\n",
    "        print(\"sobely = \", self.sobely)\n",
    "\n",
    "        print(\"sobelxx = \", self.sobelxx)\n",
    "        print(\"sobelyy = \", self.sobelyy)\n",
    "\n",
    "        sinx = torch.sin(np.pi * xv).type_as(next(self.network.parameters()))\n",
    "        dxsinx = nn.functional.conv2d(sinx.unsqueeze(0).unsqueeze(0), self.sobelx)\n",
    "        dysinx = nn.functional.conv2d(sinx.unsqueeze(0).unsqueeze(0), self.sobely)\n",
    "\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(2*2,1.2*2),\n",
    "                            subplot_kw={'aspect': 'auto'}, sharex=True, sharey=True, squeeze=True)\n",
    "        for ax_row in axs:\n",
    "            for ax in ax_row:\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "\n",
    "        im0 = axs[0][0].imshow(sinx.squeeze().detach().cpu(),cmap='jet')\n",
    "        fig.colorbar(im0, ax=axs[0,0])\n",
    "        im1 = axs[1][0].imshow(dxsinx.squeeze().detach().cpu(),cmap='jet')\n",
    "        fig.colorbar(im1, ax=axs[1,0])  \n",
    "        im1 = axs[1][1].imshow(dysinx.squeeze().detach().cpu(),cmap='jet')\n",
    "        fig.colorbar(im1, ax=axs[1,1])  \n",
    "        \n",
    "        plt.savefig(os.path.join(self.logger[0].log_dir, 'check_' + str(self.current_epoch) + '.png'))\n",
    "        # self.logger[0].experiment.add_figure('Contour Plots', fig, self.current_epoch)\n",
    "        plt.close('all')\n",
    "        exit()\n",
    "\n",
    "\n",
    "    def loss(self, u, inputs_tensor, forcing_tensor):\n",
    "\n",
    "        # self.test()\n",
    "\n",
    "        f = forcing_tensor # renaming variable\n",
    "        \n",
    "        # extract diffusivity and boundary conditions here\n",
    "        nu = inputs_tensor[:,0:1,:,:]\n",
    "        bc1 = inputs_tensor[:,1:2,:,:]\n",
    "        bc2 = inputs_tensor[:,2:3,:,:]\n",
    "\n",
    "        # apply boundary conditions\n",
    "        # u = torch.where(bc1>0.5,1.0+u*0.0,u)\n",
    "        u = torch.where(bc2>0.5,u*0.0,u)\n",
    "\n",
    "        u_x = nn.functional.conv2d(u, self.sobelx)\n",
    "        u_y = nn.functional.conv2d(u, self.sobely)\n",
    "        u_xx = nn.functional.conv2d(u, self.sobelxx)\n",
    "        u_yy = nn.functional.conv2d(u, self.sobelyy)\n",
    "        u_laplacian = u_xx + u_yy\n",
    "\n",
    "        nu_x = nn.functional.conv2d(nu, self.sobelx)\n",
    "        nu_y = nn.functional.conv2d(nu, self.sobely)\n",
    "\n",
    "        gradU_DOT_gradNU = torch.mul(u_x, nu_x) + torch.mul(u_y, nu_y)\n",
    "\n",
    "        # print(\"size of nu_x = \", nu_x.shape)\n",
    "        # print(\"size of nu[:,:,1:-1,1:-1] = \", nu[:,:,1:-1,1:-1].shape)\n",
    "        # print(\"size of u_x = \", u_x.shape)\n",
    "        # print(\"size of u_laplacian = \", u_laplacian.shape)\n",
    "        # exit()\n",
    "\n",
    "        res = f[:,:,1:-1,1:-1] + gradU_DOT_gradNU + torch.mul(nu[:,:,1:-1,1:-1], u_laplacian)\n",
    "        # print(\"res size = \", (res.view(u.shape[0], -1)).shape)\n",
    "\n",
    "        loss1 = torch.norm(res.view(u.shape[0], -1), p=1, dim=1)\n",
    "        loss2 = torch.norm(res.view(u.shape[0], -1), p=2, dim=1)\n",
    "\n",
    "        # print(\"loss1 = \", loss1, \", size = \", loss1.shape)\n",
    "        # print(\"loss2 = \", loss2, \", size = \", loss2.shape)\n",
    "        # exit()\n",
    "        # return (0.1*loss1 + 0.9*loss2)\n",
    "        return loss2\n",
    "\n",
    "        # nu_gp = self.gauss_pt_evaluation(nu)\n",
    "        # f_gp = self.gauss_pt_evaluation(f)\n",
    "        # u_gp = self.gauss_pt_evaluation(u)\n",
    "        # u_x_gp = self.gauss_pt_evaluation_der_x(u)\n",
    "        # u_y_gp = self.gauss_pt_evaluation_der_y(u)\n",
    "\n",
    "        # transformation_jacobian = self.gpw.unsqueeze(-1).unsqueeze(-1).unsqueeze(0).type_as(nu_gp)\n",
    "        # res_elmwise = transformation_jacobian * (nu_gp * (u_x_gp**2 + u_y_gp**2) - (u_gp * f_gp))\n",
    "        # res_elmwise = torch.sum(res_elmwise, 1) \n",
    "\n",
    "        # loss = torch.mean(res_elmwise)\n",
    "        # return loss\n",
    "\n",
    "    def forward(self, batch):\n",
    "        inputs_tensor, forcing_tensor = batch\n",
    "        return self.network[0], inputs_tensor, forcing_tensor\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Configure optimizer for network parameters\n",
    "        \"\"\"\n",
    "        # lr = self.learning_rate\n",
    "        opts = [torch.optim.LBFGS(self.network, lr=0.1, max_iter=4)]\n",
    "        # return opts, []\n",
    "        # opts = [torch.optim.Adam(self.network.parameters(), lr=1e-3)]\n",
    "        schd = []\n",
    "        schd = [torch.optim.lr_scheduler.MultiStepLR(opts[0], milestones=[2,5,10], gamma=0.1)]\n",
    "        return opts, schd\n",
    "    \n",
    "    def do_query(self, inputs, forcing):\n",
    "        u, inputs_tensor, forcing_tensor = self.forward((inputs.unsqueeze(0).type_as(next(self.network.parameters())), \n",
    "                                                         forcing.unsqueeze(0).type_as(next(self.network.parameters()))))\n",
    "        \n",
    "        f = forcing_tensor.squeeze().detach().cpu() # renaming variable\n",
    "        \n",
    "        # extract diffusivity and boundary conditions here\n",
    "        nu = inputs_tensor[:,0:1,:,:]\n",
    "        bc1 = inputs_tensor[:,1:2,:,:]\n",
    "        bc2 = inputs_tensor[:,2:3,:,:]        \n",
    "        # process diffusivity\n",
    "        k = nu.squeeze().detach().cpu()\n",
    "\n",
    "        # process u (by adding BC)\n",
    "        u = torch.where(bc1>0.5,1.0+u*0.0,u)\n",
    "        u = torch.where(bc2>0.5,u*0.0,u)        \n",
    "        u = u.squeeze().detach().cpu()\n",
    "        \n",
    "        return u, k, f\n",
    "    \n",
    "    def plot_contours_to_logger(self,k,f,u,u_exact):\n",
    "        diff = u - u_exact\n",
    "        # plotting        \n",
    "        fig, axs = plt.subplots(1, 5, figsize=(3*5,2),\n",
    "                            subplot_kw={'aspect': 'auto'}, sharex=True, sharey=True, squeeze=True)\n",
    "        for ax in axs:\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])              \n",
    "        \n",
    "        # print(np.linalg.norm(diff.flatten())/self.domain_size)\n",
    "        im = axs[0].imshow(f,cmap='jet')\n",
    "        fig.colorbar(im, ax=axs[0], ticks=[0.0, 4.0, 8.0, 12.0, 16.0, 20.0]); axs[0].set_title(r'$f$')\n",
    "        im = axs[1].imshow(k,cmap='jet')\n",
    "        fig.colorbar(im, ax=axs[1]); axs[1].set_title(r'$\\nu$')\n",
    "        im = axs[2].imshow(u,cmap='jet', vmin=0.0, vmax=1.0)\n",
    "        fig.colorbar(im, ax=axs[2]); axs[2].set_title(r'$u_{\\theta}$')\n",
    "        im = axs[3].imshow(u_exact,cmap='jet', vmin=0.0, vmax=1.0)\n",
    "        fig.colorbar(im, ax=axs[3]); axs[3].set_title(r'$u_{exact}$')\n",
    "        im = axs[4].imshow(diff,cmap='jet')\n",
    "        fig.colorbar(im, ax=axs[4]); axs[4].set_title(r'$u_{\\theta}-u_{exact}$')\n",
    "        # plt.show()\n",
    "        plt.savefig(os.path.join(self.logger[0].log_dir, 'contour_' + str(self.current_epoch) + '.png'))\n",
    "        self.logger[0].experiment.add_figure('Contour Plots', fig, self.current_epoch)\n",
    "        plt.close('all') \n",
    "        \n",
    "    def plot_contours(self,k,f,u,u_exact):\n",
    "        diff = u - u_exact\n",
    "        # plotting        \n",
    "        fig, axs = plt.subplots(1, 5, figsize=(3*5,2),\n",
    "                            subplot_kw={'aspect': 'auto'}, sharex=True, sharey=True, squeeze=True)\n",
    "        for ax in axs:\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])              \n",
    "        \n",
    "        # print(np.linalg.norm(diff.flatten())/self.domain_size)\n",
    "        im = axs[0].imshow(f,cmap='jet')\n",
    "        fig.colorbar(im, ax=axs[0], ticks=[0.0, 4.0, 8.0, 12.0, 16.0, 20.0]); axs[0].set_title(r'$f$')\n",
    "        im = axs[1].imshow(k,cmap='jet')\n",
    "        fig.colorbar(im, ax=axs[1]); axs[1].set_title(r'$\\nu$')\n",
    "        im = axs[2].imshow(u,cmap='jet', vmin=0.0, vmax=1.0)\n",
    "        fig.colorbar(im, ax=axs[2]); axs[2].set_title(r'$u_{\\theta}$')\n",
    "        im = axs[3].imshow(u_exact,cmap='jet', vmin=0.0, vmax=1.0)\n",
    "        fig.colorbar(im, ax=axs[3]); axs[3].set_title(r'$u_{exact}$')\n",
    "        im = axs[4].imshow(diff,cmap='jet')\n",
    "        fig.colorbar(im, ax=axs[4]); axs[4].set_title(r'$u_{\\theta}-u_{exact}$')\n",
    "        plt.show()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.network.eval()\n",
    "        inputs, forcing = self.dataset[0]\n",
    "        u, k, f = self.do_query(inputs, forcing)                \n",
    "        \n",
    "        u_exact = self.u_exact.squeeze().detach().cpu()\n",
    "        diff = u - u_exact\n",
    "        \n",
    "        self.plot_contours_to_logger(k,f,u,u_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: ./fdm-mms\n",
      "/miniconda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:148: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f95020bbd90>)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f95020bbd90>)`.\n",
      "  f\"Setting `Trainer(checkpoint_callback={checkpoint_callback})` is deprecated in v1.5 and will \"\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "2021-11-12 18:52:02.474112: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-12 18:52:02.474169: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/miniconda/lib/python3.7/site-packages/pytorch_lightning/loggers/csv_logs.py:58: UserWarning: Experiment logs directory ./fdm-mms/version_0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "  f\"Experiment logs directory {self.log_dir} exists and is not empty.\"\n",
      "\n",
      "  | Name    | Type          | Params\n",
      "------------------------------------------\n",
      "0 | network | ParameterList | 4.1 K \n",
      "------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "54        Non-trainable params\n",
      "4.2 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n",
      "/miniconda/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:111: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  30%|███       | 30/100 [00:28<01:06,  1.06it/s, loss=2.17, v_num=0_0]    "
     ]
    }
   ],
   "source": [
    "u_tensor = np.ones((1,1,64,64))\n",
    "network = torch.nn.ParameterList([torch.nn.Parameter(torch.FloatTensor(u_tensor), requires_grad=True)])\n",
    "# dataset = Dataset('example-coefficients.txt', domain_size=64)\n",
    "dataset = RectangleManufactured(domain_size=64)\n",
    "basecase = Poisson(network, dataset, batch_size=1)\n",
    "\n",
    "# ------------------------\n",
    "# 1 INIT TRAINER\n",
    "# ------------------------\n",
    "logger = pl.loggers.TensorBoardLogger('.', name=\"fdm-mms\")\n",
    "csv_logger = pl.loggers.CSVLogger(logger.save_dir, name=logger.name, version=logger.version)\n",
    "\n",
    "early_stopping = pl.callbacks.early_stopping.EarlyStopping('loss',\n",
    "    min_delta=1e-8, patience=10, verbose=False, mode='max', strict=True)\n",
    "checkpoint = pl.callbacks.model_checkpoint.ModelCheckpoint(monitor='loss',\n",
    "    dirpath=logger.log_dir, filename='{epoch}-{step}',\n",
    "    mode='min', save_last=True)\n",
    "\n",
    "trainer = Trainer(callbacks=[early_stopping],\n",
    "    checkpoint_callback=checkpoint, logger=[logger,csv_logger],\n",
    "    max_epochs=25, deterministic=True, profiler=\"simple\")\n",
    "\n",
    "# ------------------------\n",
    "# 4 Training\n",
    "# ------------------------\n",
    "\n",
    "trainer.fit(basecase)\n",
    "\n",
    "# ------------------------\n",
    "# 5 SAVE NETWORK\n",
    "# ------------------------\n",
    "torch.save(basecase.network, os.path.join(logger.log_dir, 'network.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query\n",
    "basecase.dataset[0]\n",
    "inputs, forcing = basecase.dataset[0]\n",
    "u, k, f = basecase.do_query(inputs, forcing) \n",
    "u_exact = basecase.u_exact.squeeze().detach().cpu()\n",
    "# plot\n",
    "basecase.plot_contours(k,f,u,u_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
