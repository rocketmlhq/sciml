{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment using Numpy Linear Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "In this workbook, we will look into the basics of deploying a model. For simplicity, we will consider a simple numpy linear classifier $$ \\mathbf{Y} = \\mathbf{W} \\mathbf{X} + \\mathbf{b}$$\n",
    "\n",
    "For simplicity, we will consider $\\mathbf{X}$ to be 6 dimensional ($\\mathbb{R}^6$). i.e. 1 data point $x \\in \\mathbf{X}$ will be a numpy array of shape $(1,6)$. The output $\\mathbf{Y}$ is 3 dimensional ($\\mathbb{R}^3$). Then, the weights $\\mathbf{W}$ will be a numpy array of shape $(3,6)$ and bias $\\mathbf{b}$ will be a numpy array of shape $(,3)$. \n",
    "\n",
    "In this workbook, we will demonstrate how to deploy this numpy linear classifier as a server and how to perform query on this numpy linear classifier.\n",
    "\n",
    "## 2. Imports and Dependencies.\n",
    "The few packages needed are loaded next. Particularly, `numpy`, `mlflow` will be majorly used in this tutorial. `requests` package will be used for performing query. `json` is used to post and get response from the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from mlflow import pyfunc\n",
    "\n",
    "# Setting a tracking uri to log the mlflow logs in a particular location tracked by \n",
    "from mlflow.tracking import MlflowClient\n",
    "tracking_uri = os.environ.get(\"TRACKING_URL\")\n",
    "client = MlflowClient(tracking_uri=tracking_uri)\n",
    "mlflow.set_tracking_uri(tracking_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utility function to add libraries to conda environment\n",
    "def add_libraries_to_conda_env(_conda_env,libraries=[],conda_dependencies=[]):\n",
    "    dependencies = _conda_env[\"dependencies\"]\n",
    "    dependencies = dependencies + conda_dependencies\n",
    "    pip_index = None\n",
    "    for _index,_element in enumerate(dependencies):\n",
    "        if type(_element) == dict:\n",
    "            if \"pip\" in _element.keys():\n",
    "                pip_index = _index\n",
    "                break\n",
    "    dependencies[pip_index][\"pip\"] =  dependencies[pip_index][\"pip\"] + libraries\n",
    "    _conda_env[\"dependencies\"] = dependencies\n",
    "    return _conda_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Wrapper that takes X as input using json and predicts an output Y\n",
    "class ModelWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def load_context(self,context):\n",
    "        import numpy as np\n",
    "        self.model = np.load(context.artifacts['model_path'], allow_pickle=True).tolist()\n",
    "        print(\"Model initialized\")\n",
    "    \n",
    "    def predict(self, context, model_input):\n",
    "        import numpy as np\n",
    "        import json\n",
    "        json_txt = \", \".join(model_input.columns)\n",
    "        data_list = json.loads(json_txt)\n",
    "        inputs = np.array(data_list)\n",
    "        if len(inputs.shape) == 2:\n",
    "            print('batch inference')\n",
    "            predictions = []\n",
    "            for idx in range(inputs.shape[0]):\n",
    "                prediction = np.matmul(inputs[idx,:],self.model['weights'].T) + self.model['bias']\n",
    "                predictions.append(prediction.tolist())\n",
    "        elif len(inputs.shape) == 1:\n",
    "            print('single inference')\n",
    "            predictions = self.model['weights'].T * inputs + self.model['bias']\n",
    "            predictions = predictions.tolist()\n",
    "        else:\n",
    "            raise ValueError('invalid input shape')\n",
    "        return json.dumps(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the python inference model wrapper for the server\n",
    "model_wrapper = ModelWrapper()\n",
    "env = mlflow.pytorch.get_default_conda_env()\n",
    "env = add_libraries_to_conda_env(env,libraries=['numpy'])\n",
    "\n",
    "# define the model weights randomly\n",
    "np_weights = np.random.rand(3,6)\n",
    "np_bias = np.random.rand(3)\n",
    "\n",
    "# checkpointing and logging the model in mlflow\n",
    "artifact_path = './np_model'\n",
    "np.save(artifact_path, {'weights':np_weights, 'bias':np_bias})\n",
    "model_artifacts = {\"model_path\" : artifact_path+'.npy'}\n",
    "mlflow.pyfunc.log_model(\"np_model\", python_model=model_wrapper, artifacts=model_artifacts, conda_env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deploying the model\n",
    "The above code logs a model in the experiments tab. For more info please refer [here](https://rocketml.gitbook.io/rocketml-user-guide/experiments). After deploying the model, we can obtain the model url for performing query as shown below.\n",
    "\n",
    "## 5. Query from the server\n",
    "\n",
    "There are two methods to perform query... The first is using `requests` library and the other using `curl` shell command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.81811   2.361802  2.3531516]]\n",
      "[[1.6456957 1.9675521 1.7067064]\n",
      " [2.5838118 2.8157287 2.2976384]\n",
      " [2.1801186 2.6144202 2.1953769]\n",
      " [1.488653  2.0579617 1.9867096]\n",
      " [1.809318  2.2533681 1.9978099]\n",
      " [1.6314347 2.6019633 2.2711916]\n",
      " [1.8024088 2.3680732 2.1608143]\n",
      " [1.5847387 2.1460922 1.6070927]\n",
      " [1.6557037 1.9244839 1.9006283]\n",
      " [1.6835335 2.0878038 1.7025021]\n",
      " [1.1496542 1.4508257 1.5056852]\n",
      " [1.8416998 2.6405902 2.111057 ]\n",
      " [2.2202673 2.6577232 2.1318862]\n",
      " [2.4101307 2.4593313 2.14497  ]\n",
      " [1.4908085 2.0428987 2.0579786]\n",
      " [1.6514273 2.2453768 2.2934952]\n",
      " [1.8059101 1.9135844 1.9444287]\n",
      " [1.8330411 2.6794806 2.3693244]\n",
      " [1.997308  2.4394622 2.3306658]\n",
      " [1.9428451 2.5416408 2.459957 ]]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"http://127.0.0.1:5011/invocations\"\n",
    "headers = {\"Content-Type\":\"text/csv\"}\n",
    "\n",
    "# First case, run inference on single data point\n",
    "np_array = np.random.rand(1,6).tolist()\n",
    "json_data = json.dumps(np_array)\n",
    "response = requests.post(url,data=json_data,headers=headers)\n",
    "if response.status_code == 200:\n",
    "    output = np.array(json.loads(response.json())).astype(np.float32)\n",
    "    print(output)\n",
    "else:\n",
    "    print(response.status_code)\n",
    "    print(\"REST API deployment is in progress -- please try again in a few minutes!\")\n",
    "\n",
    "# Second case, run inference on multiple data points\n",
    "np_array = np.random.rand(20,6).tolist()\n",
    "json_data = json.dumps(np_array)\n",
    "response = requests.post(url,data=json_data,headers=headers)\n",
    "if response.status_code == 200:\n",
    "    output = np.array(json.loads(response.json())).astype(np.float32)\n",
    "    print(output)\n",
    "else:\n",
    "    print(response.status_code)\n",
    "    print(\"REST API deployment is in progress -- please try again in a few minutes!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"[[1.9308286100142427, 2.58603809605743, 2.3403451985121264]]\""
     ]
    }
   ],
   "source": [
    "!curl http://127.0.0.1:5011/invocations -H 'Content-Type:text/csv' -d '[[0.6499166977064089, 0.17579454262114602, 0.2688911143313131, 0.7146591854799202, 0.6497433572112488, 0.7723469203958951]]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
